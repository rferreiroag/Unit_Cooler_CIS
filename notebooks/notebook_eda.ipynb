{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Unit Cooler Digital Twin - Exploratory Data Analysis\n\n**Project:** HVAC Unit Cooler Digital Twin  \n**Date:** 2025-11-18  \n**Dataset:** datos_combinados_entrenamiento_20251118_105234.csv\n\n## Objective\nComprehensive exploratory data analysis of the consolidated Unit Cooler experimental dataset to understand data quality, patterns, and relationships for model development."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data.data_loader import load_and_preprocess, DataLoader\n",
    "from utils.eda_utils import EDAAnalyzer, print_eda_summary\n",
    "from utils.visualization import *\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = '../data/raw/datos_combinados_entrenamiento_20251118_105234.csv'\n",
    "df, metadata = load_and_preprocess(data_path)\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Rows: {df.shape[0]:,}\")\n",
    "print(f\"Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names and types\n",
    "print(\"Column names and data types:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Descriptive statistics:\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Missing_Pct': missing_pct\n",
    "}).sort_values('Missing_Pct', ascending=False)\n",
    "\n",
    "print(\"Missing values summary:\")\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "plot_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality issues\n",
    "analyzer = EDAAnalyzer(df)\n",
    "issues = analyzer.check_data_quality_issues()\n",
    "\n",
    "print(\"Data quality issues:\")\n",
    "for issue_type, issue_data in issues.items():\n",
    "    print(f\"\\n{issue_type}:\")\n",
    "    if isinstance(issue_data, dict):\n",
    "        for k, v in list(issue_data.items())[:10]:\n",
    "            print(f\"  {k}: {v}\")\n",
    "    elif isinstance(issue_data, list):\n",
    "        for item in issue_data[:10]:\n",
    "            print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variables Analysis\n",
    "\n",
    "Key target variables:\n",
    "- **UCAOT**: Unit Cooler Air Outlet Temperature\n",
    "- **UCWOT**: Unit Cooler Water Outlet Temperature\n",
    "- **UCAF**: Unit Cooler Air Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variables statistics\n",
    "target_vars = ['UCAOT', 'UCWOT', 'UCAF']\n",
    "print(\"Target variables statistics:\")\n",
    "df[target_vars].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variables\n",
    "plot_distributions(df, target_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for target variables\n",
    "plot_boxplots(df, target_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Input Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key input variables\n",
    "input_vars = ['UCWIT', 'UCAIT', 'UCWF', 'UCAIH', 'AMBT']\n",
    "available_inputs = [v for v in input_vars if v in df.columns]\n",
    "\n",
    "print(\"Input variables statistics:\")\n",
    "df[available_inputs].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of input variables\n",
    "plot_distributions(df, available_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for key variables\n",
    "key_vars = target_vars + available_inputs\n",
    "corr_matrix = df[key_vars].corr()\n",
    "\n",
    "print(\"Correlation matrix:\")\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation heatmap\n",
    "plot_correlation_heatmap(df, variables=key_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highly correlated pairs\n",
    "high_corr = analyzer.identify_highly_correlated_pairs(threshold=0.8)\n",
    "\n",
    "print(\"Highly correlated variable pairs (|r| >= 0.8):\")\n",
    "for var1, var2, corr in high_corr:\n",
    "    print(f\"  {var1} <-> {var2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations with target variables\n",
    "target_corrs = analyzer.analyze_target_correlations(target_vars)\n",
    "\n",
    "print(\"Top correlations with each target:\")\n",
    "target_corrs.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target correlations\n",
    "plot_target_correlations(df, target_vars, top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series for key variables\n",
    "plot_time_series(df, key_vars, sample_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR method\n",
    "outliers_iqr = analyzer.detect_outliers(method='iqr', threshold=1.5)\n",
    "\n",
    "print(\"Outlier counts (IQR method, threshold=1.5):\")\n",
    "outliers_sorted = sorted(outliers_iqr.items(), key=lambda x: x[1], reverse=True)\n",
    "for var, count in outliers_sorted[:15]:\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  {var:15s}: {count:6,} ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering Preparation\n",
    "\n",
    "Calculate physics-based features for model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate temperature differences\n",
    "df_features = df.copy()\n",
    "\n",
    "# Temperature deltas\n",
    "if 'UCWIT' in df.columns and 'UCWOT' in df.columns:\n",
    "    df_features['delta_T_water'] = df['UCWIT'] - df['UCWOT']\n",
    "\n",
    "if 'UCAIT' in df.columns and 'UCAOT' in df.columns:\n",
    "    df_features['delta_T_air'] = df['UCAOT'] - df['UCAIT']\n",
    "\n",
    "# Calculate thermal power (simplified)\n",
    "Cp_water = 4186.0  # J/(kg·K)\n",
    "Cp_air = 1005.0    # J/(kg·K)\n",
    "\n",
    "if 'UCWF' in df.columns and 'delta_T_water' in df_features.columns:\n",
    "    df_features['Q_water_calc'] = df['UCWF'] * Cp_water * df_features['delta_T_water'] / 1000  # kW\n",
    "\n",
    "if 'UCAF' in df.columns and 'delta_T_air' in df_features.columns:\n",
    "    df_features['Q_air_calc'] = df['UCAF'] * Cp_air * df_features['delta_T_air'] / 1000  # kW\n",
    "\n",
    "# Calculate efficiency (if both Q values available)\n",
    "if 'Q_air_calc' in df_features.columns and 'Q_water_calc' in df_features.columns:\n",
    "    df_features['efficiency'] = df_features['Q_air_calc'] / (df_features['Q_water_calc'] + 1e-6)\n",
    "\n",
    "print(\"Engineered features:\")\n",
    "new_features = ['delta_T_water', 'delta_T_air', 'Q_water_calc', 'Q_air_calc', 'efficiency']\n",
    "available_new = [f for f in new_features if f in df_features.columns]\n",
    "df_features[available_new].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eda_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "### Data Quality\n",
    "1. **Dataset Size**: 56,211 rows × 32 columns\n",
    "2. **Missing Values**: Significant missing data in many columns (23-76%)\n",
    "   - UCSDP: 76.42% missing\n",
    "   - UCFMC: 75.75% missing\n",
    "   - UCFMV: 75.07% missing\n",
    "   - UCAIH: 72.06% missing\n",
    "   - Most other variables: ~23-33% missing\n",
    "3. **Negative Flow Values**: 12,620 negative values in UCWF (water flow)\n",
    "4. **Outliers**: Many variables show 10-30% outliers (IQR method)\n",
    "\n",
    "### Target Variables\n",
    "1. **UCAOT** (Air Outlet Temp): Mean=34.6°C, Std=58.8°C\n",
    "2. **UCWOT** (Water Outlet Temp): Mean=103.1°C, Std=211.7°C (extreme variance)\n",
    "3. **UCAF** (Air Flow): Mean=6,259, Std=17,841 (high variance)\n",
    "\n",
    "### Correlations\n",
    "1. **UCAIH** (Air Inlet Humidity) strongly negatively correlated with:\n",
    "   - UCAOT: r=-0.624\n",
    "   - UCWOT: r=-0.658\n",
    "2. **High multicollinearity** between flow measurements:\n",
    "   - UCFMS ↔ UCFMV: r=0.996\n",
    "   - UCAF ↔ UCFMV: r=0.977\n",
    "\n",
    "### Recommendations\n",
    "1. **Data Cleaning**: Address negative flow values and extreme outliers\n",
    "2. **Imputation Strategy**: Develop robust imputation for ~23-30% missing data\n",
    "3. **Feature Selection**: Remove highly correlated features to reduce multicollinearity\n",
    "4. **Physics Constraints**: Implement constraints to ensure physical validity\n",
    "5. **Stratified Sampling**: Ensure train/val/test splits represent all operational regimes\n",
    "\n",
    "### Next Steps\n",
    "1. Develop comprehensive data preprocessing pipeline\n",
    "2. Implement physics-based feature engineering\n",
    "3. Create Physics-Informed Neural Network (PINN) architecture\n",
    "4. Validate against baseline models (LinearRegression, RandomForest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}